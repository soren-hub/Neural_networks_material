{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0849d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy \n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5fd2a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10a16eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d31a517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "print(numpy.shape(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5ed84",
   "metadata": {},
   "source": [
    "![model](img/model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddf07df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "#entrada\n",
    "model.add(Dense(12, input_dim=8,kernel_initializer= \"uniform\" , activation= \"relu\" ))\n",
    "#capas profundas \n",
    "model.add(Dense(8, kernel_initializer= \"uniform\" , activation= \"relu\" ))\n",
    "#capa de salida, sigmoid por que arroja valores entre 0 y 1 \n",
    "model.add(Dense(1, kernel_initializer= \"uniform\" , activation= \"sigmoid\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d781172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= \"binary_crossentropy\", optimizer= \"adam\" , metrics=[ \"accuracy\" ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71daddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6a84fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 1/52 [..............................] - ETA: 0s - loss: 0.6936 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6802 - accuracy: 0.6245 - val_loss: 0.6746 - val_accuracy: 0.6378\n",
      "Epoch 2/200\n",
      "52/52 [==============================] - 0s 928us/step - loss: 0.6643 - accuracy: 0.6576 - val_loss: 0.6667 - val_accuracy: 0.6378\n",
      "Epoch 3/200\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.6566 - accuracy: 0.6576 - val_loss: 0.6595 - val_accuracy: 0.6378\n",
      "Epoch 4/200\n",
      "52/52 [==============================] - 0s 986us/step - loss: 0.6498 - accuracy: 0.6576 - val_loss: 0.6486 - val_accuracy: 0.6378\n",
      "Epoch 5/200\n",
      "52/52 [==============================] - 0s 936us/step - loss: 0.6394 - accuracy: 0.6615 - val_loss: 0.6388 - val_accuracy: 0.6654\n",
      "Epoch 6/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6238 - accuracy: 0.6693 - val_loss: 0.6436 - val_accuracy: 0.6299\n",
      "Epoch 7/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.6790 - val_loss: 0.6186 - val_accuracy: 0.7008\n",
      "Epoch 8/200\n",
      "52/52 [==============================] - 0s 968us/step - loss: 0.6146 - accuracy: 0.6751 - val_loss: 0.6069 - val_accuracy: 0.7008\n",
      "Epoch 9/200\n",
      "52/52 [==============================] - 0s 966us/step - loss: 0.6150 - accuracy: 0.6673 - val_loss: 0.6041 - val_accuracy: 0.6850\n",
      "Epoch 10/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5998 - accuracy: 0.6790 - val_loss: 0.5984 - val_accuracy: 0.6890\n",
      "Epoch 11/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5959 - accuracy: 0.7043 - val_loss: 0.5946 - val_accuracy: 0.7047\n",
      "Epoch 12/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5927 - accuracy: 0.6984 - val_loss: 0.5923 - val_accuracy: 0.7008\n",
      "Epoch 13/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5911 - accuracy: 0.7023 - val_loss: 0.5953 - val_accuracy: 0.6890\n",
      "Epoch 14/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.7043 - val_loss: 0.5976 - val_accuracy: 0.6772\n",
      "Epoch 15/200\n",
      "52/52 [==============================] - 0s 939us/step - loss: 0.5864 - accuracy: 0.6907 - val_loss: 0.5896 - val_accuracy: 0.6890\n",
      "Epoch 16/200\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.5905 - accuracy: 0.6984 - val_loss: 0.5859 - val_accuracy: 0.7087\n",
      "Epoch 17/200\n",
      "52/52 [==============================] - 0s 986us/step - loss: 0.5811 - accuracy: 0.7004 - val_loss: 0.5945 - val_accuracy: 0.6811\n",
      "Epoch 18/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.7160 - val_loss: 0.6161 - val_accuracy: 0.6732\n",
      "Epoch 19/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5894 - accuracy: 0.7101 - val_loss: 0.5925 - val_accuracy: 0.6811\n",
      "Epoch 20/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.7062 - val_loss: 0.5803 - val_accuracy: 0.7087\n",
      "Epoch 21/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5765 - accuracy: 0.7023 - val_loss: 0.5796 - val_accuracy: 0.6929\n",
      "Epoch 22/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.6965 - val_loss: 0.5784 - val_accuracy: 0.6969\n",
      "Epoch 23/200\n",
      "52/52 [==============================] - 0s 917us/step - loss: 0.5717 - accuracy: 0.7082 - val_loss: 0.5819 - val_accuracy: 0.6850\n",
      "Epoch 24/200\n",
      "52/52 [==============================] - 0s 963us/step - loss: 0.5729 - accuracy: 0.7101 - val_loss: 0.5772 - val_accuracy: 0.7047\n",
      "Epoch 25/200\n",
      "52/52 [==============================] - 0s 937us/step - loss: 0.5716 - accuracy: 0.7043 - val_loss: 0.5759 - val_accuracy: 0.6850\n",
      "Epoch 26/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.7043 - val_loss: 0.5753 - val_accuracy: 0.6969\n",
      "Epoch 27/200\n",
      "52/52 [==============================] - 0s 983us/step - loss: 0.5716 - accuracy: 0.6790 - val_loss: 0.5751 - val_accuracy: 0.7008\n",
      "Epoch 28/200\n",
      "52/52 [==============================] - 0s 926us/step - loss: 0.5641 - accuracy: 0.6984 - val_loss: 0.5817 - val_accuracy: 0.6772\n",
      "Epoch 29/200\n",
      "52/52 [==============================] - 0s 987us/step - loss: 0.5585 - accuracy: 0.7218 - val_loss: 0.5770 - val_accuracy: 0.7047\n",
      "Epoch 30/200\n",
      "52/52 [==============================] - 0s 949us/step - loss: 0.5603 - accuracy: 0.7160 - val_loss: 0.5968 - val_accuracy: 0.6732\n",
      "Epoch 31/200\n",
      "52/52 [==============================] - 0s 996us/step - loss: 0.5648 - accuracy: 0.7237 - val_loss: 0.5955 - val_accuracy: 0.6811\n",
      "Epoch 32/200\n",
      "52/52 [==============================] - 0s 999us/step - loss: 0.5644 - accuracy: 0.6984 - val_loss: 0.5730 - val_accuracy: 0.7008\n",
      "Epoch 33/200\n",
      "52/52 [==============================] - 0s 952us/step - loss: 0.5692 - accuracy: 0.7004 - val_loss: 0.5729 - val_accuracy: 0.7165\n",
      "Epoch 34/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.7179 - val_loss: 0.5720 - val_accuracy: 0.7008\n",
      "Epoch 35/200\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.5593 - accuracy: 0.7082 - val_loss: 0.5720 - val_accuracy: 0.7165\n",
      "Epoch 36/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.7140 - val_loss: 0.5669 - val_accuracy: 0.7047\n",
      "Epoch 37/200\n",
      "52/52 [==============================] - 0s 984us/step - loss: 0.5559 - accuracy: 0.7101 - val_loss: 0.5673 - val_accuracy: 0.7283\n",
      "Epoch 38/200\n",
      "52/52 [==============================] - 0s 982us/step - loss: 0.5565 - accuracy: 0.7101 - val_loss: 0.5947 - val_accuracy: 0.6693\n",
      "Epoch 39/200\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5547 - accuracy: 0.7179 - val_loss: 0.5647 - val_accuracy: 0.7126\n",
      "Epoch 40/200\n",
      "52/52 [==============================] - 0s 982us/step - loss: 0.5550 - accuracy: 0.7043 - val_loss: 0.5687 - val_accuracy: 0.7126\n",
      "Epoch 41/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.7257 - val_loss: 0.5586 - val_accuracy: 0.7087\n",
      "Epoch 42/200\n",
      "52/52 [==============================] - 0s 944us/step - loss: 0.5466 - accuracy: 0.7276 - val_loss: 0.5703 - val_accuracy: 0.7047\n",
      "Epoch 43/200\n",
      "52/52 [==============================] - 0s 971us/step - loss: 0.5468 - accuracy: 0.7179 - val_loss: 0.5656 - val_accuracy: 0.7047\n",
      "Epoch 44/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5576 - accuracy: 0.7198 - val_loss: 0.5557 - val_accuracy: 0.7087\n",
      "Epoch 45/200\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.5531 - accuracy: 0.7237 - val_loss: 0.5552 - val_accuracy: 0.7087\n",
      "Epoch 46/200\n",
      "52/52 [==============================] - 0s 903us/step - loss: 0.5477 - accuracy: 0.7140 - val_loss: 0.5563 - val_accuracy: 0.7244\n",
      "Epoch 47/200\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.5503 - accuracy: 0.7101 - val_loss: 0.5538 - val_accuracy: 0.7283\n",
      "Epoch 48/200\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.5456 - accuracy: 0.7121 - val_loss: 0.5543 - val_accuracy: 0.7165\n",
      "Epoch 49/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7276 - val_loss: 0.5511 - val_accuracy: 0.7244\n",
      "Epoch 50/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.7374 - val_loss: 0.5493 - val_accuracy: 0.7205\n",
      "Epoch 51/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5367 - accuracy: 0.7257 - val_loss: 0.5600 - val_accuracy: 0.7087\n",
      "Epoch 52/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5334 - accuracy: 0.7179 - val_loss: 0.5577 - val_accuracy: 0.7126\n",
      "Epoch 53/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7315 - val_loss: 0.5539 - val_accuracy: 0.7126\n",
      "Epoch 54/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5333 - accuracy: 0.7568 - val_loss: 0.5525 - val_accuracy: 0.7362\n",
      "Epoch 55/200\n",
      "52/52 [==============================] - 0s 991us/step - loss: 0.5356 - accuracy: 0.7490 - val_loss: 0.5633 - val_accuracy: 0.7047\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 970us/step - loss: 0.5354 - accuracy: 0.7471 - val_loss: 0.5443 - val_accuracy: 0.7205\n",
      "Epoch 57/200\n",
      "52/52 [==============================] - 0s 968us/step - loss: 0.5388 - accuracy: 0.7393 - val_loss: 0.5460 - val_accuracy: 0.7244\n",
      "Epoch 58/200\n",
      "52/52 [==============================] - 0s 985us/step - loss: 0.5304 - accuracy: 0.7374 - val_loss: 0.5490 - val_accuracy: 0.7205\n",
      "Epoch 59/200\n",
      "52/52 [==============================] - 0s 989us/step - loss: 0.5325 - accuracy: 0.7451 - val_loss: 0.5547 - val_accuracy: 0.7165\n",
      "Epoch 60/200\n",
      "52/52 [==============================] - 0s 969us/step - loss: 0.5299 - accuracy: 0.7529 - val_loss: 0.5506 - val_accuracy: 0.7244\n",
      "Epoch 61/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.7451 - val_loss: 0.5451 - val_accuracy: 0.7244\n",
      "Epoch 62/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.7412 - val_loss: 0.5392 - val_accuracy: 0.7205\n",
      "Epoch 63/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7451 - val_loss: 0.5604 - val_accuracy: 0.7087\n",
      "Epoch 64/200\n",
      "52/52 [==============================] - 0s 955us/step - loss: 0.5297 - accuracy: 0.7412 - val_loss: 0.5414 - val_accuracy: 0.7362\n",
      "Epoch 65/200\n",
      "52/52 [==============================] - 0s 966us/step - loss: 0.5219 - accuracy: 0.7510 - val_loss: 0.5396 - val_accuracy: 0.7244\n",
      "Epoch 66/200\n",
      "52/52 [==============================] - 0s 972us/step - loss: 0.5300 - accuracy: 0.7432 - val_loss: 0.5542 - val_accuracy: 0.7087\n",
      "Epoch 67/200\n",
      "52/52 [==============================] - 0s 989us/step - loss: 0.5190 - accuracy: 0.7510 - val_loss: 0.5537 - val_accuracy: 0.7087\n",
      "Epoch 68/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5168 - accuracy: 0.7490 - val_loss: 0.5398 - val_accuracy: 0.7283\n",
      "Epoch 69/200\n",
      "52/52 [==============================] - 0s 988us/step - loss: 0.5262 - accuracy: 0.7412 - val_loss: 0.5386 - val_accuracy: 0.7323\n",
      "Epoch 70/200\n",
      "52/52 [==============================] - 0s 971us/step - loss: 0.5385 - accuracy: 0.7315 - val_loss: 0.5405 - val_accuracy: 0.7402\n",
      "Epoch 71/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.7607 - val_loss: 0.5467 - val_accuracy: 0.7244\n",
      "Epoch 72/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7451 - val_loss: 0.5541 - val_accuracy: 0.7244\n",
      "Epoch 73/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.7412 - val_loss: 0.5401 - val_accuracy: 0.7205\n",
      "Epoch 74/200\n",
      "52/52 [==============================] - 0s 900us/step - loss: 0.5126 - accuracy: 0.7549 - val_loss: 0.5366 - val_accuracy: 0.7244\n",
      "Epoch 75/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7510 - val_loss: 0.5352 - val_accuracy: 0.7244\n",
      "Epoch 76/200\n",
      "52/52 [==============================] - 0s 967us/step - loss: 0.5115 - accuracy: 0.7510 - val_loss: 0.5397 - val_accuracy: 0.7441\n",
      "Epoch 77/200\n",
      "52/52 [==============================] - 0s 985us/step - loss: 0.5085 - accuracy: 0.7588 - val_loss: 0.5492 - val_accuracy: 0.7362\n",
      "Epoch 78/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7665 - val_loss: 0.5420 - val_accuracy: 0.7205\n",
      "Epoch 79/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7665 - val_loss: 0.5337 - val_accuracy: 0.7283\n",
      "Epoch 80/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5124 - accuracy: 0.7432 - val_loss: 0.5426 - val_accuracy: 0.7244\n",
      "Epoch 81/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.7471 - val_loss: 0.5520 - val_accuracy: 0.7165\n",
      "Epoch 82/200\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.5137 - accuracy: 0.7529 - val_loss: 0.5358 - val_accuracy: 0.7323\n",
      "Epoch 83/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7471 - val_loss: 0.5391 - val_accuracy: 0.7559\n",
      "Epoch 84/200\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.4964 - accuracy: 0.7607 - val_loss: 0.5419 - val_accuracy: 0.7559\n",
      "Epoch 85/200\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.5058 - accuracy: 0.7607 - val_loss: 0.5473 - val_accuracy: 0.7323\n",
      "Epoch 86/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7646 - val_loss: 0.5477 - val_accuracy: 0.7165\n",
      "Epoch 87/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7665 - val_loss: 0.5362 - val_accuracy: 0.7441\n",
      "Epoch 88/200\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.5139 - accuracy: 0.7626 - val_loss: 0.5351 - val_accuracy: 0.7402\n",
      "Epoch 89/200\n",
      "52/52 [==============================] - 0s 940us/step - loss: 0.4941 - accuracy: 0.7607 - val_loss: 0.5319 - val_accuracy: 0.7402\n",
      "Epoch 90/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.7510 - val_loss: 0.5368 - val_accuracy: 0.7638\n",
      "Epoch 91/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7646 - val_loss: 0.5626 - val_accuracy: 0.7441\n",
      "Epoch 92/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7432 - val_loss: 0.5507 - val_accuracy: 0.7441\n",
      "Epoch 93/200\n",
      "52/52 [==============================] - 0s 979us/step - loss: 0.5038 - accuracy: 0.7704 - val_loss: 0.5380 - val_accuracy: 0.7402\n",
      "Epoch 94/200\n",
      "52/52 [==============================] - 0s 958us/step - loss: 0.4973 - accuracy: 0.7626 - val_loss: 0.5301 - val_accuracy: 0.7441\n",
      "Epoch 95/200\n",
      "52/52 [==============================] - 0s 920us/step - loss: 0.5063 - accuracy: 0.7490 - val_loss: 0.5485 - val_accuracy: 0.7362\n",
      "Epoch 96/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.7646 - val_loss: 0.5394 - val_accuracy: 0.7520\n",
      "Epoch 97/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.7724 - val_loss: 0.5356 - val_accuracy: 0.7362\n",
      "Epoch 98/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7665 - val_loss: 0.5362 - val_accuracy: 0.7441\n",
      "Epoch 99/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.7626 - val_loss: 0.5483 - val_accuracy: 0.7362\n",
      "Epoch 100/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7665 - val_loss: 0.5313 - val_accuracy: 0.7520\n",
      "Epoch 101/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7646 - val_loss: 0.5355 - val_accuracy: 0.7362\n",
      "Epoch 102/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7685 - val_loss: 0.5788 - val_accuracy: 0.7205\n",
      "Epoch 103/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.7626 - val_loss: 0.5471 - val_accuracy: 0.7362\n",
      "Epoch 104/200\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.4890 - accuracy: 0.7490 - val_loss: 0.5349 - val_accuracy: 0.7402\n",
      "Epoch 105/200\n",
      "52/52 [==============================] - 0s 951us/step - loss: 0.4805 - accuracy: 0.7724 - val_loss: 0.5323 - val_accuracy: 0.7441\n",
      "Epoch 106/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7588 - val_loss: 0.5495 - val_accuracy: 0.7323\n",
      "Epoch 107/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7607 - val_loss: 0.5405 - val_accuracy: 0.7402\n",
      "Epoch 108/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7510 - val_loss: 0.5366 - val_accuracy: 0.7323\n",
      "Epoch 109/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7510 - val_loss: 0.5414 - val_accuracy: 0.7480\n",
      "Epoch 110/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7782 - val_loss: 0.5366 - val_accuracy: 0.7520\n",
      "Epoch 111/200\n",
      "52/52 [==============================] - 0s 988us/step - loss: 0.4830 - accuracy: 0.7685 - val_loss: 0.5700 - val_accuracy: 0.7205\n",
      "Epoch 112/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7568 - val_loss: 0.5348 - val_accuracy: 0.7402\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7588 - val_loss: 0.5302 - val_accuracy: 0.7520\n",
      "Epoch 114/200\n",
      "52/52 [==============================] - 0s 966us/step - loss: 0.4822 - accuracy: 0.7626 - val_loss: 0.5447 - val_accuracy: 0.7244\n",
      "Epoch 115/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7568 - val_loss: 0.5426 - val_accuracy: 0.7323\n",
      "Epoch 116/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7782 - val_loss: 0.5505 - val_accuracy: 0.7283\n",
      "Epoch 117/200\n",
      "52/52 [==============================] - 0s 961us/step - loss: 0.4799 - accuracy: 0.7704 - val_loss: 0.5383 - val_accuracy: 0.7402\n",
      "Epoch 118/200\n",
      "52/52 [==============================] - 0s 985us/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.5722 - val_accuracy: 0.7008\n",
      "Epoch 119/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7607 - val_loss: 0.5441 - val_accuracy: 0.7283\n",
      "Epoch 120/200\n",
      "52/52 [==============================] - 0s 937us/step - loss: 0.4772 - accuracy: 0.7626 - val_loss: 0.5361 - val_accuracy: 0.7480\n",
      "Epoch 121/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7646 - val_loss: 0.5360 - val_accuracy: 0.7362\n",
      "Epoch 122/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7802 - val_loss: 0.5334 - val_accuracy: 0.7402\n",
      "Epoch 123/200\n",
      "52/52 [==============================] - 0s 987us/step - loss: 0.4768 - accuracy: 0.7665 - val_loss: 0.5673 - val_accuracy: 0.7441\n",
      "Epoch 124/200\n",
      "52/52 [==============================] - 0s 990us/step - loss: 0.4654 - accuracy: 0.7840 - val_loss: 0.5351 - val_accuracy: 0.7520\n",
      "Epoch 125/200\n",
      "52/52 [==============================] - 0s 905us/step - loss: 0.4697 - accuracy: 0.7588 - val_loss: 0.5469 - val_accuracy: 0.7323\n",
      "Epoch 126/200\n",
      "52/52 [==============================] - 0s 983us/step - loss: 0.4674 - accuracy: 0.7665 - val_loss: 0.5341 - val_accuracy: 0.7362\n",
      "Epoch 127/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7607 - val_loss: 0.5359 - val_accuracy: 0.7480\n",
      "Epoch 128/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7802 - val_loss: 0.5329 - val_accuracy: 0.7362\n",
      "Epoch 129/200\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.4766 - accuracy: 0.7549 - val_loss: 0.5412 - val_accuracy: 0.7362\n",
      "Epoch 130/200\n",
      "52/52 [==============================] - 0s 930us/step - loss: 0.4592 - accuracy: 0.7918 - val_loss: 0.5612 - val_accuracy: 0.7480\n",
      "Epoch 131/200\n",
      "52/52 [==============================] - 0s 914us/step - loss: 0.4689 - accuracy: 0.7568 - val_loss: 0.5356 - val_accuracy: 0.7362\n",
      "Epoch 132/200\n",
      "52/52 [==============================] - 0s 942us/step - loss: 0.4665 - accuracy: 0.7646 - val_loss: 0.5399 - val_accuracy: 0.7244\n",
      "Epoch 133/200\n",
      "52/52 [==============================] - 0s 948us/step - loss: 0.4723 - accuracy: 0.7646 - val_loss: 0.5314 - val_accuracy: 0.7520\n",
      "Epoch 134/200\n",
      "52/52 [==============================] - 0s 903us/step - loss: 0.4675 - accuracy: 0.7704 - val_loss: 0.5371 - val_accuracy: 0.7402\n",
      "Epoch 135/200\n",
      "52/52 [==============================] - 0s 971us/step - loss: 0.4680 - accuracy: 0.7802 - val_loss: 0.5646 - val_accuracy: 0.7047\n",
      "Epoch 136/200\n",
      "52/52 [==============================] - 0s 937us/step - loss: 0.4725 - accuracy: 0.7704 - val_loss: 0.5443 - val_accuracy: 0.7244\n",
      "Epoch 137/200\n",
      "52/52 [==============================] - 0s 988us/step - loss: 0.4671 - accuracy: 0.7704 - val_loss: 0.5595 - val_accuracy: 0.7441\n",
      "Epoch 138/200\n",
      "52/52 [==============================] - 0s 949us/step - loss: 0.4652 - accuracy: 0.7821 - val_loss: 0.5372 - val_accuracy: 0.7362\n",
      "Epoch 139/200\n",
      "52/52 [==============================] - 0s 996us/step - loss: 0.4646 - accuracy: 0.7724 - val_loss: 0.5326 - val_accuracy: 0.7402\n",
      "Epoch 140/200\n",
      "52/52 [==============================] - 0s 974us/step - loss: 0.4637 - accuracy: 0.7607 - val_loss: 0.5398 - val_accuracy: 0.7362\n",
      "Epoch 141/200\n",
      "52/52 [==============================] - 0s 979us/step - loss: 0.4647 - accuracy: 0.7782 - val_loss: 0.5350 - val_accuracy: 0.7441\n",
      "Epoch 142/200\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.4633 - accuracy: 0.7782 - val_loss: 0.6057 - val_accuracy: 0.7244\n",
      "Epoch 143/200\n",
      "52/52 [==============================] - 0s 957us/step - loss: 0.4696 - accuracy: 0.7743 - val_loss: 0.5393 - val_accuracy: 0.7520\n",
      "Epoch 144/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7840 - val_loss: 0.5297 - val_accuracy: 0.7441\n",
      "Epoch 145/200\n",
      "52/52 [==============================] - 0s 956us/step - loss: 0.4707 - accuracy: 0.7646 - val_loss: 0.5337 - val_accuracy: 0.7520\n",
      "Epoch 146/200\n",
      "52/52 [==============================] - 0s 953us/step - loss: 0.4658 - accuracy: 0.7549 - val_loss: 0.5455 - val_accuracy: 0.7283\n",
      "Epoch 147/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7665 - val_loss: 0.5537 - val_accuracy: 0.7520\n",
      "Epoch 148/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7840 - val_loss: 0.5344 - val_accuracy: 0.7598\n",
      "Epoch 149/200\n",
      "52/52 [==============================] - 0s 996us/step - loss: 0.4559 - accuracy: 0.7782 - val_loss: 0.5285 - val_accuracy: 0.7520\n",
      "Epoch 150/200\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.4567 - accuracy: 0.7782 - val_loss: 0.5449 - val_accuracy: 0.7323\n",
      "Epoch 151/200\n",
      "52/52 [==============================] - 0s 983us/step - loss: 0.4529 - accuracy: 0.7724 - val_loss: 0.5444 - val_accuracy: 0.7323\n",
      "Epoch 152/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7704 - val_loss: 0.5280 - val_accuracy: 0.7362\n",
      "Epoch 153/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7802 - val_loss: 0.5277 - val_accuracy: 0.7441\n",
      "Epoch 154/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.5367 - val_accuracy: 0.7362\n",
      "Epoch 155/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7763 - val_loss: 0.5385 - val_accuracy: 0.7441\n",
      "Epoch 156/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7938 - val_loss: 0.5429 - val_accuracy: 0.7402\n",
      "Epoch 157/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7840 - val_loss: 0.5353 - val_accuracy: 0.7283\n",
      "Epoch 158/200\n",
      "52/52 [==============================] - 0s 995us/step - loss: 0.4557 - accuracy: 0.7899 - val_loss: 0.5436 - val_accuracy: 0.7402\n",
      "Epoch 159/200\n",
      "52/52 [==============================] - 0s 993us/step - loss: 0.4523 - accuracy: 0.7763 - val_loss: 0.5702 - val_accuracy: 0.7244\n",
      "Epoch 160/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7802 - val_loss: 0.5429 - val_accuracy: 0.7244\n",
      "Epoch 161/200\n",
      "52/52 [==============================] - 0s 970us/step - loss: 0.4617 - accuracy: 0.7704 - val_loss: 0.5387 - val_accuracy: 0.7520\n",
      "Epoch 162/200\n",
      "52/52 [==============================] - 0s 995us/step - loss: 0.4558 - accuracy: 0.7802 - val_loss: 0.5313 - val_accuracy: 0.7402\n",
      "Epoch 163/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7724 - val_loss: 0.5318 - val_accuracy: 0.7677\n",
      "Epoch 164/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7704 - val_loss: 0.5525 - val_accuracy: 0.7283\n",
      "Epoch 165/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7763 - val_loss: 0.5340 - val_accuracy: 0.7677\n",
      "Epoch 166/200\n",
      "52/52 [==============================] - 0s 990us/step - loss: 0.4592 - accuracy: 0.7821 - val_loss: 0.5903 - val_accuracy: 0.7008\n",
      "Epoch 167/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7782 - val_loss: 0.5302 - val_accuracy: 0.7402\n",
      "Epoch 168/200\n",
      "52/52 [==============================] - 0s 937us/step - loss: 0.4522 - accuracy: 0.7802 - val_loss: 0.5767 - val_accuracy: 0.7323\n",
      "Epoch 169/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7957 - val_loss: 0.5466 - val_accuracy: 0.7165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7918 - val_loss: 0.5404 - val_accuracy: 0.7165\n",
      "Epoch 171/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7743 - val_loss: 0.5309 - val_accuracy: 0.7638\n",
      "Epoch 172/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7918 - val_loss: 0.5456 - val_accuracy: 0.7283\n",
      "Epoch 173/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7743 - val_loss: 0.5584 - val_accuracy: 0.7244\n",
      "Epoch 174/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7840 - val_loss: 0.5478 - val_accuracy: 0.7402\n",
      "Epoch 175/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7821 - val_loss: 0.5495 - val_accuracy: 0.7441\n",
      "Epoch 176/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7782 - val_loss: 0.5439 - val_accuracy: 0.7520\n",
      "Epoch 177/200\n",
      "52/52 [==============================] - 0s 942us/step - loss: 0.4536 - accuracy: 0.7802 - val_loss: 0.5922 - val_accuracy: 0.7165\n",
      "Epoch 178/200\n",
      "52/52 [==============================] - 0s 997us/step - loss: 0.4770 - accuracy: 0.7763 - val_loss: 0.5792 - val_accuracy: 0.7205\n",
      "Epoch 179/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7763 - val_loss: 0.5728 - val_accuracy: 0.7402\n",
      "Epoch 180/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7802 - val_loss: 0.5350 - val_accuracy: 0.7638\n",
      "Epoch 181/200\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.4509 - accuracy: 0.7763 - val_loss: 0.5539 - val_accuracy: 0.7244\n",
      "Epoch 182/200\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.4606 - accuracy: 0.7957 - val_loss: 0.5877 - val_accuracy: 0.7323\n",
      "Epoch 183/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7724 - val_loss: 0.5398 - val_accuracy: 0.7520\n",
      "Epoch 184/200\n",
      "52/52 [==============================] - 0s 978us/step - loss: 0.4533 - accuracy: 0.7996 - val_loss: 0.5518 - val_accuracy: 0.7323\n",
      "Epoch 185/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7646 - val_loss: 0.6352 - val_accuracy: 0.7008\n",
      "Epoch 186/200\n",
      "52/52 [==============================] - 0s 959us/step - loss: 0.4624 - accuracy: 0.7918 - val_loss: 0.5328 - val_accuracy: 0.7402\n",
      "Epoch 187/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7685 - val_loss: 0.5269 - val_accuracy: 0.7480\n",
      "Epoch 188/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7821 - val_loss: 0.5272 - val_accuracy: 0.7402\n",
      "Epoch 189/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7802 - val_loss: 0.5407 - val_accuracy: 0.7520\n",
      "Epoch 190/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7743 - val_loss: 0.5269 - val_accuracy: 0.7677\n",
      "Epoch 191/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7996 - val_loss: 0.5377 - val_accuracy: 0.7441\n",
      "Epoch 192/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7879 - val_loss: 0.5461 - val_accuracy: 0.7283\n",
      "Epoch 193/200\n",
      "52/52 [==============================] - 0s 989us/step - loss: 0.4438 - accuracy: 0.7802 - val_loss: 0.5279 - val_accuracy: 0.7598\n",
      "Epoch 194/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7938 - val_loss: 0.5517 - val_accuracy: 0.7283\n",
      "Epoch 195/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7802 - val_loss: 0.5262 - val_accuracy: 0.7520\n",
      "Epoch 196/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7860 - val_loss: 0.5300 - val_accuracy: 0.7717\n",
      "Epoch 197/200\n",
      "52/52 [==============================] - 0s 976us/step - loss: 0.4390 - accuracy: 0.7879 - val_loss: 0.5429 - val_accuracy: 0.7402\n",
      "Epoch 198/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7782 - val_loss: 0.5318 - val_accuracy: 0.7441\n",
      "Epoch 199/200\n",
      "52/52 [==============================] - 0s 989us/step - loss: 0.4339 - accuracy: 0.7879 - val_loss: 0.5584 - val_accuracy: 0.7283\n",
      "Epoch 200/200\n",
      "52/52 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7938 - val_loss: 0.5529 - val_accuracy: 0.7362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d435373d08>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test,y_test),epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5e2a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 748us/step - loss: 0.5529 - accuracy: 0.7362\n",
      "accuracy: 73.62%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test,y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd91b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2946eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver=\"liblinear\")\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25327f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc038e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[141,  21],\n",
       "       [ 41,  51]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ea0985a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7559055118110236"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91ad0769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 257.44, 'Etiqueta de prediccion')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names = [0,1]\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap=\"Blues_r\", fmt=\"g\")\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title(\"Matriz de confusion\", y=1.1)\n",
    "plt.ylabel(\"Etiqueta Actual\")\n",
    "plt.xlabel(\"Etiqueta de prediccion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8090810d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
