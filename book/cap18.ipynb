{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5820ee",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351d4ad",
   "metadata": {},
   "source": [
    "Dado un conjunto de datos de imágenes en escala de grises con el tamaño estandarizado de $32 \\times 32$ píxeles cada una, una red neuronal feedforward tradicional requeriría 1.024 pesos de entrada (más un sesgo). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50b541",
   "metadata": {},
   "source": [
    "## Construcción de las redes neuronales convolucionales.\n",
    "\n",
    "Hay tres tipos de capas en una red neuronal convolucional:\n",
    "1. Capas convolucionales.\n",
    "2. Capas de agrupación.\n",
    "3. Capas totalmente conectadas.\n",
    "\n",
    "## Capas convolucionales.\n",
    "Las capas convolucionales se componen de filtros y mapas de características.\n",
    "### Filtros o kernel. \n",
    "Una matriz que se va aplicando a cada pixel de la imagen.Los valores de la matriz seran calculados mediante el entrenamiento de la red.\n",
    " <img src=\"img/filtro.jpg\" height=\"600px\" width=\"400px\" />\n",
    "\n",
    "### Mapas de características.\n",
    "El mapa de características es la salida de un filtro aplicado a la capa anterior.\n",
    "Si el tamaño de la capa anterior no es claramente divisible por el tamaño del campo receptivo de los filtros y el tamaño de la zancada.En este caso, se pueden utilizar técnicas como el relleno cero para inventar entradas falsas con valores cero para que el campo receptivo las lea.\n",
    "### Capas de agrupación.\n",
    "Cada filtro genera una capa por lo que si aplicamos varios filtros nos saldran varias capas generando capas de agrupación.\n",
    "Por ejemplo si de entrada tenemos una imagen normal a color, con sus tres canales rgb, esto se podría interpretar como que en realidad tenemos tres mapas de características diferentes donde se han detectado elementos en rojo en verde y en azul a la vez tenemos tres mapas de características donde si ahora realizamos la operación de convolución con 16 filtros(por ejemplo) podremos detectar 16 caracteristicas diferentes, que notarán como resultado 16 mapas de características. 16 imágenes que ahora pasarán a ser el input de la siguiente capa convolucional.\n",
    "<img src=\"img/convolucion.png\" height=\"600px\" width=\"400px\" />\n",
    "\n",
    "### Capas totalmente conectadas.\n",
    "\n",
    "Las capas totalmente conectadas son las capas normales de las redes neuronales planas de tipo feedforward. Estas capas pueden tener una función de activación no lineal o una activación softmax para dar salida a las probabilidades de predicción de clase. Las capas totalmente conectadas se utilizan al final de la red después de que las capas convolucionales y de agrupación hayan realizado la extracción y consolidación de características. Se utilizan para crear combinaciones finales no lineales de características y para realizar predicciones por parte de la red.\n",
    "<img src=\"img/fully.png\" height=\"600px\" width=\"400px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7236d1c",
   "metadata": {},
   "source": [
    "#####  Ejemplo: \n",
    "###### Image Input Data.\n",
    "Supongamos que tenemos un conjunto de datos de imágenes en escala de grises. Cada imagen tiene el mismo tamaño de 32 píxeles de ancho y 32 píxeles de alto, y los valores de los píxeles están entre 0 y 255, por ejemplo, una matriz de $32 \\times 32 \\times 1$ o $1.024$ píxeles. Los datos de entrada de la imagen se expresan como una matriz tridimensional de $anchura \\times altura \\times canales$. Si en nuestro ejemplo utilizáramos imágenes en color, tendríamos 3 canales para los valores de los píxeles rojos, verdes y azules, por ejemplo $32 \\times 32 \\times 3$.\n",
    "###### Convolutional Layer\n",
    "Definimos una capa convolucional con 10 filtros y cada uno de 5 píxeles de ancho y 5 píxeles de alto. Dado que cada filtro es de $5 \\times 5$ (25 valores), podemos calcular que cada uno requerirá 25 + 1 pesos de entrada (más 1 para la entrada de sesgo). Si corremos el filtro $5 \\times 5$ a través de la imagen de entrada, se obtendrá un mapa de características de $28 \\times 28$ (784 valores por imagen) que reprensentara el mapa de caracterizticas. \n",
    "<img src=\"img/filtro.png\" height=\"600px\" width=\"400px\" />\n",
    "Tenemos 10 filtros, por lo que son 10 mapas de características $28 \\times 28$ diferentes o $7,840$ salidas que se crearán para una imagen. Finalmente, sabemos que tenemos 26 entradas por filtro, 10 filtros y $28 \\times 28$ valores de salida para calcular por filtro, por lo tanto tenemos un total de $26 \\times 10 \\times 28 \\times 28$ o $203,840$ conexiones en nuestra capa convolucional.\n",
    "###### Capa de agrupación.\n",
    "Definimos una capa de agrupación con un filtro con una anchura de 2 entradas y una altura de 2 entradas.\n",
    "También utilizamos una longitud de 2 para garantizar que no haya solapamiento. Esto resulta en mapas de características que son la mitad del tamaño de los mapas de características de entrada.De 10 mapas de características diferentes de $28 \\times 28$ como entrada a 10 mapas de características diferentes de $14 \\times 14$ como salida. Utilizaremos una operación max() para cada campo receptivo de modo que la activación sea el valor máximo de entrada.\n",
    "###### Capa totalmente conectada.\n",
    "Por último, podemos aplicar la funcion flatten a los mapas de características cuadrados en una capa plana tradicional totalmente conectada.Podemos definir la capa totalmente conectada con 200 neuronas ocultas, cada una con $10 \\times 14 \\times 14$ conexiones de entrada, o 1.960 + 1 pesos por neurona. Esto supone un total de 392.200 conexiones y pesos a aprender en esta capa. Podemos utilizar una función sigmoide o softmax para dar salida a las probabilidades de los valores de las posibles clase.\n",
    "<img src=\"img/ejemplo.png\" height=\"120px\" width=\"800px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216154f9",
   "metadata": {},
   "source": [
    "#### Buenas prácticas a tener en cuenta a la hora de aplicar CNN.\n",
    "\n",
    "* **Dimensiones del parche de entrada**: El valor por defecto es 2D para las imágenes, pero podría ser 1D como en el caso de las palabras de una frase, o 3D en el caso de un vídeo que añada una dimensión temporal.\n",
    "\n",
    "* **Tamaño del parche**: El parche debe ser lo más pequeño posible, pero lo suficientemente grande para ver las características de los datos de entrada. Es habitual utilizar $3 \\times 3$ en imágenes pequeñas y $5 \\times 5$ o $7 \\times 7$ y más en imágenes de mayor tamaño. \n",
    "\n",
    "* **Longitud del desplazamiento del parche**: Utilice el stride por defecto de 1. Es fácil de entender y no necesita relleno para manejar el parche que cae fuera del borde de sus imágenes. Esto podría aumentarse a 2 o más para imágenes más grandes.\n",
    "\n",
    "* **Número de filtros**: Los filtros son los detectores de características. Generalmente se utilizan menos filtros en la capa de entrada y cada vez más filtros en las capas más profundas.\n",
    "\n",
    "* **Relleno**: Se fija en cero y se llama relleno cero cuando se leen datos que no son de entrada. Esto es útil cuando no se puede o no se quiere estandarizar el tamaño de la imagen de entrada o cuando se quiere utilizar tamaños de parches y de zancada que no dividen perfectamente el tamaño de la imagen de entrada.\n",
    "\n",
    "* **Agrupación**: El pooling es un proceso de generalización para reducir el sobreajuste. El tamaño del campo receptivo se establece casi siempre en $2 \\times 2$ con un stride de 2 para descartar el 75% de las activaciones de la salida de la capa anterior.\n",
    "\n",
    "* **Preparación de los datos**: Considerar la estandarización de los datos de entrada, tanto las dimensiones de las imágenes como los valores de los píxeles.\n",
    "\n",
    "* **Patrón de arquitectura**: Es habitual que las capas de la arquitectura de su red estén estandarizadas. Puede ser una, dos o algún número de capas convolucionales seguidas de una capa de agrupación. Esta estructura puede repetirse una o más veces. Por último, las capas totalmente conectadas suelen utilizarse sólo en el extremo de salida y pueden apilarse a una, dos o más profundidades.\n",
    "\n",
    "* **Abandono**: Las CNN tienen la costumbre de sobreajustarse, incluso con capas de agrupación.Se debería utilizar el dropout, por ejemplo, entre las capas totalmente conectadas y, quizás, después de agrupar las capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db91e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef7c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211491b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book_new",
   "language": "python",
   "name": "book_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
