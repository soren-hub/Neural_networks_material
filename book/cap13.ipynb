{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d6fa572",
   "metadata": {},
   "source": [
    "En ocaciones nos encontraremos con entrenamientos de moledos que demoraran mucho tiempo, si quieremos detener el entrenamiento para continuarlo en otro momento podemos hacer uso del siguiente metodo: \n",
    "\n",
    "-guardar la estructura de la red neuronal con la función to_json().\n",
    "-guardar los pesos de la red con la función save_weights().\n",
    "-esta informacion quedara guardada en el directorio local.\n",
    "-para cargar el modelo de la red solo hay que importar la función model_from_json()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71290574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json #to save the model \n",
    "import numpy\n",
    "import os\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8356ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"C:/Users/joaqu/Desktop/proyecto/ensayos/datos/pima-indians-diabetes.csv\",\n",
    "                        delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61c3421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer= \"uniform\" , activation= \"relu\" ))\n",
    "model.add(Dense(8, kernel_initializer= \"uniform\" , activation= \"relu\" ))\n",
    "model.add(Dense(1, kernel_initializer= \"uniform\" , activation= \"sigmoid\" ))\n",
    "model.compile(loss= \"binary_crossentropy\" , optimizer= \"adam\" , metrics=[ \"accuracy\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75e2fb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20698ad1b48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ba2b7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 78.12%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "380ecfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67305d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open( \"model.json\" , \"r\" )\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67323b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79e4f7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#load the weights from the last training \n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b48c5eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 78.12%\n"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss= \"binary_crossentropy\" , optimizer= \"rmsprop\" , metrics=[ \"accuracy\" ])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print (\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the evaluation of both models is the same, the information, \n",
    "#both the model structure and the weights, was successfully saved and loaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc6e9c",
   "metadata": {},
   "source": [
    "Tambien los modelos se pueden guardar con formato YAML con la funtion model.yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4991480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f47d418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_yaml\n",
    "# later...\n",
    "# load YAML and create model\n",
    "yaml_file = open(\"model.yaml\",\"r\")\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e2215be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 78.12%\n"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss= \"binary_crossentropy\" , optimizer= \"rmsprop\" , metrics=[ \"accuracy\" ])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print (\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80b873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
